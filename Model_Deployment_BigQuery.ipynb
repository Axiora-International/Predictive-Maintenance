{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Notebook Purpose:\n",
        "This notebook demonstrates a robust machine learning inference pipeline connecting a trained model to data stored in Google BigQuery.\n",
        "\n",
        "**It covers:**\n",
        "\n",
        "1. Fetching and cleaning data from BigQuery.\n",
        "\n",
        "2. Mapping data columns to the modelâ€™s expected feature names.\n",
        "\n",
        "3. Handling missing values, unknown columns, and datatype mismatches.\n",
        "\n",
        "4. Running inference using a pre-trained model.\n",
        "\n",
        "5. Generating a health report and writing predictions back to BigQuery.\n",
        "\n",
        "The pipeline is designed to be robust and fail-safe, preventing runtime errors due to evolving data schemas or missing values."
      ],
      "metadata": {
        "id": "rzE9ZqG3bCdl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imports & Configuration**"
      ],
      "metadata": {
        "id": "ag4lpQj7L-hi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "PApXjvFsPVxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import re\n",
        "import sys\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List, Dict, Optional\n",
        "\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.cloud import bigquery\n",
        "from google.api_core.exceptions import GoogleAPIError\n",
        "\n",
        "# Logging Setup\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
        "    handlers=[logging.StreamHandler(sys.stdout)]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "# Configuration\n",
        "@dataclass\n",
        "class Config:\n",
        "    PROJECT_ID: str = \"crown-486620\"\n",
        "    DATASET_ID: str = \"crown1\"\n",
        "    SOURCE_TABLE: str = \"Machine Failure Data\"\n",
        "    PRED_TABLE: str = \"machine_failure_predictions\"\n",
        "    MODEL_PATH: str = \"final_machine_failure_model.pkl\"\n",
        "\n",
        "    OPTIMAL_THRESHOLD: float = 0.78\n",
        "\n",
        "    # Columns to explicitly remove before processing\n",
        "    COLUMNS_TO_DROP: List[str] = field(default_factory=lambda: [\n",
        "        'Machine failure', 'logit', 'HDF', 'OSF', 'PWF', 'TWF', 'RNF'\n",
        "    ])\n",
        "\n",
        "    # Mapping: { Clean_Column_Name_in_BQ : Column_Name_Expected_by_Model }\n",
        "    COLUMN_MAPPING: Dict[str, str] = field(default_factory=lambda: {\n",
        "        \"Process temperature\": \"Process temperature [K]\",\n",
        "        \"Rotational speed\": \"Rotational speed [rpm]\",\n",
        "        \"Torque\": \"Torque [Nm]\",\n",
        "        \"Tool wear\": \"Tool wear [min]\",\n",
        "        \"Temp_diff\": \"Temp_diff\",\n",
        "        \"Power_norm\": \"Power_norm\",\n",
        "        \"Tool_wear_norm\": \"Tool_wear_norm\",\n",
        "        \"Type_encoded\": \"Type_encoded\"\n",
        "    })\n",
        "\n",
        "    @property\n",
        "    def source_full_path(self) -> str:\n",
        "        return f\"{self.PROJECT_ID}.{self.DATASET_ID}.{self.SOURCE_TABLE}\"\n",
        "\n",
        "    @property\n",
        "    def dest_full_path(self) -> str:\n",
        "        return f\"{self.PROJECT_ID}.{self.DATASET_ID}.{self.PRED_TABLE}\"\n",
        "\n",
        "    @property\n",
        "    def expected_features(self) -> List[str]:\n",
        "        return list(self.COLUMN_MAPPING.values())\n",
        "\n",
        "\n",
        "# Helper Functions\n",
        "def load_model(path: str):\n",
        "    \"\"\"Loads the serialized model from disk.\"\"\"\n",
        "    try:\n",
        "        model = joblib.load(path)\n",
        "        logger.info(f\"Model loaded successfully from {path}\")\n",
        "        return model\n",
        "    except FileNotFoundError:\n",
        "        logger.error(f\"Model file not found at {path}\")\n",
        "        sys.exit(1)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to load model: {e}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "def fetch_data(client: bigquery.Client, query: str) -> pd.DataFrame:\n",
        "    \"\"\"Fetches data from BigQuery safely.\"\"\"\n",
        "    try:\n",
        "        df = client.query(query).to_dataframe()\n",
        "        if df.empty:\n",
        "            logger.warning(\"Check: Source table is empty. Exiting.\")\n",
        "            sys.exit(0)\n",
        "        logger.info(f\"Data fetched. Shape: {df.shape}\")\n",
        "        return df\n",
        "    except GoogleAPIError as e:\n",
        "        logger.error(f\"BigQuery fetch failed: {e}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "def clean_column_names(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Normalizes column names by stripping units and whitespace.\"\"\"\n",
        "    df.columns = df.columns.str.strip()\n",
        "    # Remove contents inside [] and ()\n",
        "    df.columns = df.columns.str.replace(r\"\\[.*?\\]\", \"\", regex=True)\n",
        "    df.columns = df.columns.str.replace(r\"\\(.*?\\)\", \"\", regex=True)\n",
        "    # Collapse multiple spaces to one\n",
        "    df.columns = df.columns.str.replace(r\"\\s+\", \" \", regex=True)\n",
        "    # Strip again to handle trailing spaces after regex\n",
        "    df.columns = df.columns.str.strip()\n",
        "    return df\n",
        "\n",
        "def preprocess_features(df: pd.DataFrame, config: Config) -> pd.DataFrame:\n",
        "    \"\"\"Prepares the feature matrix X matching model requirements.\"\"\"\n",
        "\n",
        "    # 1. Drop known unnecessary columns\n",
        "    df_clean = df.drop(columns=config.COLUMNS_TO_DROP, errors='ignore').copy()\n",
        "\n",
        "    # 2. Normalize raw column names (remove units like [K] so we can match keys)\n",
        "    df_clean = clean_column_names(df_clean)\n",
        "\n",
        "    # 3. Rename columns to match Model Expectations specifically\n",
        "    renamed_cols = {}\n",
        "    for clean_name, model_name in config.COLUMN_MAPPING.items():\n",
        "        # Case-insensitive lookup\n",
        "        matching_cols = [c for c in df_clean.columns if clean_name.lower() in c.lower()]\n",
        "\n",
        "        if matching_cols:\n",
        "            renamed_cols[matching_cols[0]] = model_name\n",
        "        else:\n",
        "            logger.warning(f\"Expected feature base '{clean_name}' not found in data.\")\n",
        "\n",
        "    df_clean = df_clean.rename(columns=renamed_cols)\n",
        "\n",
        "    # 4. Create Final Feature Matrix (X)\n",
        "    X = pd.DataFrame(index=df_clean.index)\n",
        "\n",
        "    for feature in config.expected_features:\n",
        "        if feature in df_clean.columns:\n",
        "            X[feature] = pd.to_numeric(df_clean[feature], errors='coerce')\n",
        "        else:\n",
        "            logger.warning(f\"Missing feature '{feature}'. Filling with 0.\")\n",
        "            X[feature] = 0.0\n",
        "\n",
        "    # 5. Handle NaNs\n",
        "    if X.isnull().values.any():\n",
        "        logger.info(\"Imputing missing values with batch median.\")\n",
        "        X = X.fillna(X.median())\n",
        "        X = X.fillna(0) # Fallback if median fails (e.g. all NaNs)\n",
        "\n",
        "    return X[config.expected_features] # Enforce order\n",
        "\n",
        "\n",
        "# Health Report of model\n",
        "def generate_health_report(df: pd.DataFrame, proba_col: str, pred_col: str):\n",
        "    total = len(df)\n",
        "    failures = df[pred_col].sum()\n",
        "    failure_rate = (failures / total) * 100\n",
        "    avg_confidence = df[proba_col].mean()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"MODEL INFERENCE HEALTH REPORT\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Total Machines Scanned : {total}\")\n",
        "    print(f\"Predicted Failures     : {failures}\")\n",
        "    print(f\"Failure Rate           : {failure_rate:.2f}%\")\n",
        "    print(f\"Avg Failure Prob       : {avg_confidence:.4f}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Distribution Check\n",
        "    print(\"Probability Distribution:\")\n",
        "    print(df[proba_col].describe().to_string())\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    if failure_rate > 20:\n",
        "        print(\"ALERT: High failure rate detected (>20%). Check input features.\")\n",
        "    elif failure_rate == 0:\n",
        "        print(\"ALERT: Zero failures predicted. Model might be too conservative.\")\n",
        "    else:\n",
        "        print(\"Prediction rate looks within normal operational bounds.\")\n",
        "\n",
        "    print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "    if failures > 0:\n",
        "        print(\"TOP 5 MACHINES AT RISK:\")\n",
        "        cols_to_show = [c for c in ['Product ID', 'UDI', proba_col] if c in df.columns]\n",
        "        print(df.sort_values(by=proba_col, ascending=False)[cols_to_show].head(5).to_string(index=False))\n",
        "\n",
        "\n",
        "# Main Pipeline\n",
        "def run_pipeline():\n",
        "    cfg = Config()\n",
        "    bq_client = bigquery.Client(project=cfg.PROJECT_ID)\n",
        "\n",
        "    # 1. Load Resources\n",
        "    print(\"Loading model...\")\n",
        "    model = load_model(cfg.MODEL_PATH)\n",
        "\n",
        "    # 2. Fetch Data\n",
        "    print(f\"Fetching data from {cfg.source_full_path}...\")\n",
        "    query = f\"SELECT * FROM `{cfg.source_full_path}`\"\n",
        "    df_raw = fetch_data(bq_client, query)\n",
        "\n",
        "    # 3. Preprocess\n",
        "    X = preprocess_features(df_raw, cfg)\n",
        "\n",
        "    # 4. Inference\n",
        "    print(\"Running inference...\")\n",
        "    try:\n",
        "        y_proba = model.predict_proba(X)[:, 1]\n",
        "        y_pred = (y_proba > cfg.OPTIMAL_THRESHOLD).astype(int)\n",
        "\n",
        "        # Attach predictions to dataframe\n",
        "        df_raw['failure_probability'] = y_proba\n",
        "        df_raw['predicted_machine_failure'] = y_pred\n",
        "\n",
        "        # ---PRINT THE REPORT TO TERMINAL ---\n",
        "        generate_health_report(df_raw, 'failure_probability', 'predicted_machine_failure')\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Inference failed: {e}\")\n",
        "        raise\n",
        "\n",
        "    # 5. Export\n",
        "    print(f\"Saving predictions to {cfg.dest_full_path}...\")\n",
        "    try:\n",
        "        job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\")\n",
        "        job = bq_client.load_table_from_dataframe(\n",
        "            df_raw,\n",
        "            cfg.dest_full_path,\n",
        "            job_config=job_config\n",
        "        )\n",
        "        job.result()\n",
        "        print(\"Pipeline Finished Successfully.\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"BigQuery write failed: {e}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "run_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UapYiKc-R7B_",
        "outputId": "22716489-c3f7-4824-9e5a-9572ccb987e5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model...\n",
            "Fetching data from crown-486620.crown1.Machine Failure Data...\n",
            "Running inference...\n",
            "\n",
            "==================================================\n",
            "MODEL INFERENCE HEALTH REPORT\n",
            "==================================================\n",
            "Total Machines Scanned : 10000\n",
            "Predicted Failures     : 294\n",
            "Failure Rate           : 2.94%\n",
            "Avg Failure Prob       : 0.1080\n",
            "--------------------------------------------------\n",
            "Probability Distribution:\n",
            "count    10000.000000\n",
            "mean         0.107981\n",
            "std          0.211855\n",
            "min          0.000124\n",
            "25%          0.004091\n",
            "50%          0.014629\n",
            "75%          0.083163\n",
            "max          0.995519\n",
            "--------------------------------------------------\n",
            "Prediction rate looks within normal operational bounds.\n",
            "==================================================\n",
            "\n",
            "TOP 5 MACHINES AT RISK:\n",
            " failure_probability\n",
            "            0.995519\n",
            "            0.994964\n",
            "            0.992644\n",
            "            0.991783\n",
            "            0.990709\n",
            "Saving predictions to crown-486620.crown1.machine_failure_predictions...\n",
            "Pipeline Finished Successfully.\n"
          ]
        }
      ]
    }
  ]
}